{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96566950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#title: amenities_osm.ipynb\n",
    "# get amenities per district meeting certain criteria from openstreetmap\n",
    "# first get the district relation ids from OSM\n",
    "# then sort them in alphabetical order of name\n",
    "# then for each district get the amenities of interest within the district boundary\n",
    "# then filter by certain criteria (e.g. name contains certain keywords)\n",
    "# update so that few cells can be rerun with manually updating the attempt of OT request that failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbc4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# get district relation ids of Andhra Pradesh (rel_id: 2022095) from OSM\n",
    "#\n",
    "\n",
    "import requests\n",
    "\n",
    "# %%\n",
    "# Define the Overpass API endpoint and query\n",
    "overpass_url = \"https://overpass-api.de/api/interpreter\"\n",
    "\n",
    "# Your Overpass Turbo query\n",
    "\n",
    "# Compose QT query\n",
    "query=\"\"\"\n",
    "[out:csv(::id, name)][timeout:60];\n",
    "area(%d)->.searchArea;\n",
    "(   relation[\"boundary\"=\"administrative\"][\"admin_level\"=\"5\"](area.searchArea););\n",
    "out body;\n",
    "\n",
    "\"\"\" % (3600000000 +2022095)\n",
    "# %%\n",
    "# Send the request to Overpass API\n",
    "response = requests.post(overpass_url, data={\"data\": query})\n",
    "\n",
    "# Check for successful response\n",
    "if response.status_code == 200:\n",
    "    print(\"âœ… Query executed successfully.\")\n",
    "else:\n",
    "    raise Exception(f\"Overpass API request failed with status code {response.status_code}\")\n",
    "\n",
    "# %%\n",
    "# get the \"response.content\" into a pandas dataframe\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "df = pd.read_csv(StringIO(response.text), sep='\\t')  \n",
    "\n",
    "# rename '@id' column to 'relation_id'\n",
    "df.rename(columns={'@id': 'relation_id'}, inplace=True)\n",
    "# sort by name\n",
    "df = df.sort_values(by='name').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faad22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation so that next two cells can be rerun, if the api requests fail in between\n",
    "import time\n",
    "amenity_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bffa82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually initialise and run this and next cell, till the processing is complete\n",
    "# note the index for which the http response failed from the log of responses, update dist_index to <dist_index_failed-1> and df['relation_id'][<dist_index failed-1>: <length of df>] abd rerun this and next cell\n",
    "dist_index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun the above cell after suitably modifying the above cell. Then rerun this cell, if processing is interrupted \n",
    "for rel in df['relation_id'][0:len(df)]:\n",
    "    dist_index =dist_index+1 \n",
    "    print(f\"Processing relation_id: {rel}, district_index: {dist_index} of {len(df)}\")\n",
    "    # Your Overpass Turbo query\n",
    "\n",
    "    # Compose QT query\n",
    "    query=\"\"\"\n",
    "    [out:csv(::id, ::type,  ::lat, ::lon, name)]\n",
    "    [timeout:90];\n",
    "    area(%d)->.searchArea;\n",
    "    (\n",
    "    nw\n",
    "        [office=government]\n",
    "        [name]\n",
    "        (area.searchArea);\n",
    "    );\n",
    "    out center;\n",
    "\n",
    "    \"\"\" % (3600000000 +rel)\n",
    "    # %%\n",
    "    attempt=1\n",
    "    print(f\"Try query for relation_id: {rel}\")  \n",
    "    # Send the request to Overpass API\n",
    "    response = requests.post(overpass_url, data={\"data\": query})\n",
    "\n",
    "    while response.status_code != 200:\n",
    "\n",
    "            print(f\" Query failed, attempt: {attempt} response status: {response.status_code}\")\n",
    "            if (attempt>3):\n",
    "                raise Exception(f\"Overpass API request failed with status code after several tries {response.status_code}\")\n",
    "            else:\n",
    "                print(f\"Will wait for 10 seconds and retry query\")         \n",
    "            time.sleep(10)  # wait for 10 seconds before retrying\n",
    "            attempt=attempt+1    \n",
    "            response = requests.post(overpass_url, data={\"data\": query}) \n",
    "    # Check for successful response\n",
    "    if response.status_code == 200:\n",
    "        print(f\" Query success, attempt: {attempt} response status: {response.status_code}\")\n",
    "    else:\n",
    "        raise Exception(f\"Overpass API request failed with status code {response.status_code}\")\n",
    "\n",
    "    # %%\n",
    "    # get the \"response.content\" into a pandas dataframe\n",
    "    import pandas as pd\n",
    "    from io import StringIO\n",
    "    ddf = pd.read_csv(StringIO(response.text), sep='\\t')\n",
    "\n",
    "    # remove rows where name does not contain 'Sachi' ignoring case\n",
    "    mask=ddf['name'].str.contains('Sachi', case=False, na=False)\n",
    "    ddf=ddf[mask]    \n",
    "    ddf['district']=rel\n",
    "    ddf['district_name']=df[df['relation_id']==rel]['name'].values[0]\n",
    "    #append to amenity_df dataframe\n",
    "    try:\n",
    "        amenity_df = pd.concat([amenity_df, ddf], ignore_index=True)\n",
    "    except NameError:\n",
    "        amenity_df = ddf \n",
    "    time.sleep(5)  # to avoid overloading the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize amenity_df by 'district_name' and 'type' and display counts\n",
    "district_counts = amenity_df.groupby(['district_name']).size()\n",
    "# total number of amenities found\n",
    "total_amenities =  amenity_df.groupby(['district_name']).size().sum()\n",
    "print(f\"Total number of amenities found: {total_amenities}\")\n",
    "\n",
    "print(district_counts)\n",
    "# count total number of amenities found\n",
    "print(f\"Total number of districts with amenities: {len(district_counts)}\")\n",
    "\n",
    "# list zero count districts by district_name not in df['district_name']\n",
    "zero_count_districts = df[~df['name'].isin(amenity_df['district_name'])]['name'].tolist()\n",
    "print(\"Districts with zero amenities found:\")\n",
    "print(zero_count_districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize amenity_df by 'district_name' and 'type' and display counts\n",
    "type_counts = amenity_df.groupby(['@type','district_name']).size()\n",
    "print(type_counts)\n",
    "# type of amenities\n",
    "total_type_amenities=amenity_df.groupby(['@type']).size()\n",
    "print(total_type_amenities)\n",
    "# total number of amenities found\n",
    "total_amenities =  amenity_df.groupby(['@type','district_name']).size().sum()\n",
    "print(f\"Total number of amenities found: {total_amenities}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
