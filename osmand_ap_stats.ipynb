{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d1572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title: osmand_ap_stats.ipynb\n",
    "# gets size of india_andhrapradesh osmand download file size over time from archive.org\n",
    "# input:  \"data/osmand_ap_stats.csv\"\n",
    "# output: visualisation of stats\n",
    "# output: updating input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a09e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10869349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "file_path=Path(\"data/osmand_ap_stats.csv\")\n",
    "if file_path.exists():\n",
    "    print(f\"The path '{file_path}' exists, will append any newdata.\")\n",
    "    df = pd.read_file(file_path)\n",
    "    df.head()\n",
    "    \n",
    "else:\n",
    "    print(f\"The path '{file_path}' does not exist, will create if I get new data.\")\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc2b66d",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Overpass API request failed with status code 503",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Query executed successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverpass API request failed with status code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m response\n",
      "\u001b[0;31mException\u001b[0m: Overpass API request failed with status code 503"
     ]
    }
   ],
   "source": [
    "# check for existence of backups on archive\n",
    "osmand_downloads_uri= 'download.osmand.net/list.php'\n",
    "# wayback machine cdx search url \n",
    "# wayback_url= 'http://web.archive.org/cdx/search/cdx?url='archive.org&from=2010&to=2011'\n",
    "# get osmand download page captures \n",
    "wayback_url='http://web.archive.org/cdx/search/cdx?url='+osmand_downloads_uri+'&from=2015&to=2025&output=json'\n",
    "row_filterexp=r'^India_andhra-pradesh'\n",
    "# get response\n",
    "# %%\n",
    "# Send the request to Overpass API\n",
    "response = requests.get(wayback_url)\n",
    "\n",
    "# Check for successful response\n",
    "if response.status_code == 200:\n",
    "    print(\"✅ Query executed successfully.\")\n",
    "else:\n",
    "    raise Exception(f\"Overpass API request failed with status code {response.status_code}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "# Convert the JSON response directly to a DataFrame\n",
    "df = pd.read_json(io.StringIO(response.text))\n",
    "\n",
    "# 2. Assign the first row to the column headers\n",
    "new_header = df.iloc[0]  # grabs the first row (index 0)\n",
    "df.columns = new_header # set the new headers\n",
    "\n",
    "# 3. Remove the first row from the data\n",
    "df = df[1:]\n",
    "\n",
    "# 4. (Optional) Reset the index so it starts from 0 again\n",
    "df = df.reset_index(drop=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c62c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ts=df['timestamp'][0]\n",
    "max_ts=df['timestamp'].iloc[-1]\n",
    "print(f'number of captures: {len(df)}; min_timestamp:{min_ts}; max_timestamp:{max_ts}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cab56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# The format corresponding to YYYYMMDDHHMMSS\n",
    "format_pattern = '%Y%m%d%H%M%S'\n",
    "\n",
    "# Convert the string to a datetime object\n",
    "min_ts_object= datetime.strptime(min_ts, format_pattern)\n",
    "max_ts_object= datetime.strptime(max_ts, format_pattern)\n",
    "\n",
    "# Print the resulting datetime object and its type\n",
    "print(f\"Datetime object: {min_ts_object}\")\n",
    "print(f\"Type: {type(min_ts_object)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5effc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas lxml beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "# Path to your CSV file (change 'data.csv' to your file name or path)\n",
    "capture_df=pd.DataFrame() \n",
    "# 'MS' frequency generates the start of each month (Month Start)\n",
    "for dt in pd.date_range(start=min_ts_object, end=max_ts_object, freq='MS'):\n",
    "    dt_pattern=dt.strftime(\"^%Y%m\")\n",
    "    print(f'processing archived page {dt_pattern}')\n",
    "    # get the first timestamp in df ['timestamp] that contains dt_str\n",
    "\n",
    "    # 1. Create a boolean Series indicating which rows match the regex\n",
    "    matches= df['timestamp'].str.contains(dt_pattern,regex=True,na=False)\n",
    "    # 2. Find the index of the first True value\n",
    "    # idxmax() returns the first index of the maximum value (True is max)\n",
    "    first_match_index = matches.idxmax()\n",
    "\n",
    "    # 3. Check if any match was found before attempting to access the row\n",
    "    if matches.any():\n",
    "        capture_ts = df.loc[first_match_index]['timestamp']\n",
    "        capture_url= df.loc[first_match_index]['original']\n",
    "        wayback_url='http://web.archive.org/web/'+capture_ts+'/'+capture_url\n",
    "        print(wayback_url)\n",
    "        # get captured page\n",
    "        # %%\n",
    "        # Send the request to Overpass API\n",
    "        response = requests.get(wayback_url)\n",
    "\n",
    "        # Check for successful response\n",
    "        if response.status_code == 200:\n",
    "            print(\"✅ Query executed successfully.\")\n",
    "            # Parse the HTML content using BeautifulSoup\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            # Find the first h1 tag\n",
    "            first_h1 = soup.find('h1')\n",
    "\n",
    "            # Use find_next_sibling() to find the next 'table' tag\n",
    "            # This works if they are direct siblings (no other tags in between)\n",
    "            table_after_first_h1 = first_h1.find_next_sibling('table')\n",
    "\n",
    "            if table_after_first_h1:\n",
    "                print(\"Found table after the first h1 (using find_next_sibling):\")\n",
    "                # Convert the specific table (as a string) into a pandas DataFrame\n",
    "                # read_html returns a list, so we access the first element [0]\n",
    "                page_df = pd.read_html(io.StringIO(str(table_after_first_h1)))[0]\n",
    "                #check if india related file rows exist\n",
    "                page_df=page_df[page_df['File'].str.contains(r'^India_andhra-pradesh',case=False, regex=True)]\n",
    "                if len(page_df)>=1 :\n",
    "                    capture_df = pd.concat([capture_df, page_df], ignore_index=True)\n",
    "                    print(f\"record(s) added {dt_pattern}\")\n",
    "                    break\n",
    "                    sleep(5)\n",
    "\n",
    "            else:\n",
    "                print(\"No immediate sibling table found after the first h1 using find_next_sibling.\")\n",
    "        else:\n",
    "            print(f\"response-code from archive {response.status_code}\")            \n",
    "    else:\n",
    "        print(\"No matching archive page for timestamp found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
